# 计算机系统漫游:rocket:

**计算机系统**是由硬件和系统软件组成的，它们共同工作来运行应用程序。系统的具体实现方式在不断变化，但内在概念没有改变——所有的计算机系统组件与功能都是相似的。

本次漫游，我们将通过跟踪 `hello` 程序的生命周期来进行——被程序员创建、到在系统上运行、到输出信息，最后终止。

```c
// hello.c
#include <stdio.h>

int main() {
    printf("Hello world!\n");
    return 0;
}
```



### 1.1 信息就是位+上下文

`hello` 程序的生命周期从一个源程序开始，源程序实际上是一个由0和1组成的位（比特）序列，每 8 个比特被称为一个**字节**。大部分现代计算机系统都使用 **ASCII** 标准来表示文本字符，这种方式让我们得以用一个唯一的单字节大小的整数值来表示每个字符，`hello.c`也不例外。这种表示方法说明了**一个基本思想——系统中所有信息都是由一串比特表示的，区分不同数据对象的唯一方法就是通过这些数据对象的上下文来判断。**



### 1.2 程序被其他程序翻译成不同的格式

编译程序：

```shell
linux> gcc -o hello hello.c
```



`hello` 程序的生命周期始于一个高级C语言程序，但为了在系统上运行我们需要把这些人类易懂的 C 语句用其他程序翻译为一系列低级机器语言指令。这些指令按照**可执行目标程序**的格式打好包，并以二进制磁盘文件的形式存放。

翻译过程分为四个阶段，执行这四个阶段的程序（**预处理器**、**编译器**、**汇编器**和**链接器**）一起构成了**编译系统**。

![](/notes/img/1.1.png)

- **预处理阶段**  **预处理器**根据已字符 # 开头的命令修改原始的 C 程序（将读取到的头文件信息直接插入程序文本中，得到以 `.i` 结尾的另一个 C 程序）

- **编译阶段**  **编译器**将 `hello.i` 翻译成文本文件 `hello.s`，它包含一个**汇编语言程序**。该程序包含函数 `main` 的定义：

  ```
  main:
  	subq	$8, %rsp
  	movl	$.LC0, %edi
  	call	puts
  	movl	$0, %eax
  	addq	$8, %rsp
  	ret
  ```

  *汇编语言非常有用！它为不同高级语言和不同编译器提供了通用的输出语句*

- **汇编阶段**  **汇编器**将 `hello.s` 翻译成机器语言指令，把这些指令打包成一种叫做**可重定位目标程序**的格式，并将结果保存在一个二进制形式的目标文件 `hello.o` 中。

- **链接阶段**  `hello` 程序调用了标准 C 库中的 `printf` 函数，它存在于一个名为 `printf.o` 的单独的预编译好了的目标文件中，而这个文件由**链接器**合并到 `hello.o`程序中，最后得到 `hello` 文件。`hello` 文件是一个**可执行目标文件**，可以被加载到内存中由系统执行。



### 1.3 了解编译系统如何工作是大有益处的

对于 `hello.c` 这样简单的程序，我们可以依靠编译系统生成正确有效的机器代码。但是程序员仍然有必要进一步了解编译系统是如何工作的。

- **优化程序性能**  现代编译器已经非常成熟，但为了做出更好的编码选择，我们仍然需要了解一些机器代码以及编译器将 C 语句转化成机器代码的方式—— `switch` 还是 `if-else`？`while` 还是 `for`？指针引用还是数组索引？本地变量还是引用传参......

- **理解链接时出现的错误**  一些最麻烦的程序错误常常与链接器操作有关。无法解析引用是什么意思？静态变量和全局变量有何区别？全局变量重名会发生什么......

- **避免安全漏洞**

  

### 1.4 处理器读并解释储存在内存中的指令

此时我们已经成功获取了可执行目标文件 `hello`！接下来让我们看看运行它的时候发生了什么。

```
linux> ./hello
Hello, world!
linux>
```



#### 1.4.1 系统的硬件组成

![](/notes/img/1.2.png)

- **总线**  贯穿整个系统的是一组电子管道，称作**总线**，它携带信息字节并负责在各个部件间传递。通常总线被设计成传送定长的字节块，也就是**字**。字中的字节数（即**字长**）是一个基本的系统参数，一般为 4 或 8 个字节（32 位或64 位）。
- **I/O 设备**  I/O 设备是系统与外界的桥梁。每个 I/O设备都通过一个**控制器/适配器**与 I/O 总线相连以传递信息。
- **主存**  主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。
  - 物理上，主存是由一组**动态随机存取存储器（DRAM）** 组成的。
  - 逻辑上，存储器是一个线性的字节数组，每个字节都有其唯一的地址。
- **处理器**  **中央处理单元（CPU）**，简称处理器，是解释执行存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为**程序计数器（PC）**。在任何时刻 PC 都指向主存中的某条机器语言指令（即含该指令的地址）。在系统运行过程中，处理器一直在不断执行 PC 指向的指令，再更新 PC 使其指向下一条指令。执行指令围绕着主存、**寄存器文件** 和 **算术/逻辑单元（ALU）** 进行。寄存器文件由一些单个字长的寄存器组成，是一个小的存储设备；ALU计算新的数据和地址值。下面是一些 CPU 的可能操作：
  - 加载：从主存复制一个字节或一个字到寄存器，以覆盖寄存器原来的内容。
  - 存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容。
  - 操作：将两个寄存器的内容复制到 ALU，ALU 对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容。
  - 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，以覆盖原来的值。

#### 1.4.2 运行 hello 程序

前面简单描述了系统的硬件组成和操作，现在让我们看看运行程序时发生了什么。

初始时，shell 程序将我们输入的命令逐一读入寄存器，再把它存放到内存中。

![](/notes/img/1.3.png)

当我们敲下回车键，shell 程序知道我们已经结束了命令输入，然后 shell 执行一系列指令来加载可执行的 `hello` 文件。这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存，数据包括即将输出的 `Hello, world!`。

利用**直接存储器存取（DMA）** 技术，数据可以不经过 CPU 直接从磁盘到达主存。

![](/notes/img/1.4.png)

一旦 hello 的代码和数据被加载到主存，CPU 就开始执行 hello 程序的 main 程序中的机器语言指令。这些指令将 `"Hello world!\n"` 字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备并最终显示在屏幕上。

![](/notes/img/1.5.png)

### 1.5 高速缓存至关重要

在以上简单的示例中我们看见了**一个重要的问题，即系统花费了大量的时间把信息从一个地方转移到另一个地方。** 让我们复盘一下：

- `hello` 程序的机器指令最初存在磁盘上，程序加载的时候它们被复制到了主存。

- 当 CPU 处理程序的时候，指令又从主存复制到 CPU。

- 数据串 `"Hello, world!\n"` 开始在磁盘上，然后被复制到主存，最后从主存复制到现实设备。

对程序员来说，这些复制就是开销，减慢了程序“真正”的工作。所以，**系统设计者的一个主要目标就是使这些复制操作尽快完成。**

**根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高于同类低速设备。** 例如一个寄存器文件可能只存储几百字节的信息，主存里却可以存储几十亿字节；然而 CPU 从寄存器里读数据比从主存中读取几乎要快上 100 倍。随着半导体技术的发展，这样的差距还在不断增大。

为了解决这样的矛盾，系统设计者采用了更小更快的存储设备——**高速缓存存储器（cache memory）** 作为暂时的集结区域，存放 CPU 近期可能会需要的信息。

![](/notes/img/1.6.png)

- 存储器分层：位于 CPU 上的 **L1高速缓存** 的容量达到数万字节，访问速度几乎与访问寄存器持平；**L2高速缓存** 的容量达到数十数百万字节，通过一条特殊的总线连接到处理器，访问速度比 L1 慢 5 倍但仍然比访问主存快 5~10 倍。L1 和 L2 高速缓存使用 **静态随机访问存储器（SRAM）** 实现。处理能力更强大的系统甚至还存在 L3 高速缓存。

- **高速缓存的局部性原理：** 程序具有访问局部区域里的数据和代码的趋势。
  
  - 空间局部性：在最近的未来要用到的信息（指令和数据），很可能与现在正在使用的信息在存储空间上是邻近的。

  - 时间局部性：在最近的未来要用到的信息，很可能是现在正在使用的信息。

*本书的一个重要结论就是，程序员可以通过对高速缓存的理解将程序的性能提高一个数量级*

### 1.6 存储设备形成层次结构

在 CPU 与大而慢的设备（如主存）间插入一个小而快的设备（如高速缓存)的想法已经成为了一个普遍的观念。实际上，每个计算机系统的存储设备都组织成了一个**存储器层次结构。**

![](/notes/img/1.7.png)

*在这个层次结构中从上至下，访问速度越来越慢，容量越来越大。*

存储器层次结构的**主要思想是上一层的存储器作为低一层存储器的高速缓存。**

### 1.7 操作系统管理硬件

我们可以把操作系统看作是应用软件和硬件之间插入的一层软件，所有应用程序对硬件的操作尝试都必须通过操作系统。

![](/notes/img/1.8.png)

操作系统的两个基本功能

- 防止硬件被失控的应用程序滥用。

- 向应用程序提供简单一致的机制来控制复杂又通常大不相同的低级硬件设备。

![](/notes/img/1.9.png)

操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个基本功能。

- 文件是对 I/O 设备的抽象表示。

- 虚拟内存是对主存和磁盘 I/O 设备的抽象表示。

- 进程是对 CPU、主存和 I/O 设备的抽象表示。


#### 1.7.1 进程

诸如 `hello` 这样的程序在现代系统上运行的时候，操作系统总会给我们一种假象——系统上好像只有这个程序在运行。这些假象是通过**进程**——这个计算机科学最重要和最成功的概念之一——来实现的。

进程是操作系统对一个正在运行的程序的一种抽象。

- **并发运行：**  一个进程的指令和另一个进程的指令是交错执行的。这种交错执行的机制被称为**上下文切换**。

- 操作系统保持跟踪进程运行所需的所有状态信息，即**上下文**。

- 进程转换是由操作系统**内核**管理的，内核是操作系统代码常驻内存的部分，它不是一个进程，而是系统管理全部进程所用代码和数据结构的集合。


#### 1.7.2 线程

在线代系统中，一个进程实际上可以由多个称为**线程**的执行单元组成。每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。因为多线程之间比多进程更容易共享数据并且线程比进程一般更加高效，所以线程正在成为更加重要的编程模型。


#### 1.7.3 虚拟内存

**虚拟内存**是一个抽象概念，它为每个进程提供了一种假象，即每个进程都在独占主存。每个进程看到的内存都是一致的，称为**虚拟地址空间**。

![](/notes/img/1.10.png)

每个进程看到的虚拟地址空间都由大量准确定义的区构成：

- 程序代码与数据

- 堆

- 共享库

- 栈

- 内核虚拟内存


#### 1.7.4 文件

**文件**就是字节序列，仅此而已。每个 I/O 设备甚至于网络都可以算作文件，这个简单而精致的概念十分强大，因为它向应用程序提供了一个统一的视图来看待系统中所有种类的 I/O 设备。

### 1.8 系统之间利用网络通信

漫游至此，我们一直把系统视为一个孤立的硬件-软件集合体，但实际上现代系统经常通过网络和其他系统连接到一起。从一个单独的系统来看，网络可视为一个将信息从一台机器复制到另一台机器的 I/O 设备，将数据发送给其它设备或读取其他设备发送来的数据。

![](/notes/img/1.11.png)

### 1.9 重要主题

在此，让我们小结一下这次计算机系统漫游。这次讨论得出的一个很重要的观点是，**系统不只是硬件，而是硬件与系统软件互相交织的集合体，它们必须共同协作以达到运行应用程序的最终目的。**

作为本章的结束，让我们再次强调几个贯穿计算机系统所有方面的重要概念。

#### 1.9.1 Amdahl定律

- **主要思想**  当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。

若系统执行某应用程序需要时间 $T_{old}$，假设系统某部分所需执行时间与该时间的比例为 $\alpha$，而该部分性能提升比例为 $k$。即该部分初始所需时间为 $(\alpha T_{old})$，现在所需时间为$(\alpha T_{old})/k$。故总执行时间为
$$T_{new}=(1-\alpha )T_{old}+(\alpha T_{old})/k=T_{old}[(1-\alpha)+\alpha/k]$$

故可得加速比：
$$S=\frac{T_{old}}{T_{new}}=\frac{1}{(1-\alpha)+\alpha/k}$$


#### 1.9.2 并发与并行

数字计算机的整个历史中，有两个需求是驱动进步的持续动力：

- 我们想要计算机做的更多。

- 我们想要计算机运行得更快。

当 CPU 能够同时做更多的事情时，这两个因素都会改进。我们用的术语**并发**是一个通用的概念，指一个同时具有多个活动的系统；而术语**并行**指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用，在此我们按照系统层次结构中由高到低的顺序重点强调三个层次。

##### 1.线程级并发

构建在线程这个抽象上，我们能够设计出同时有多个程序执行的系统，这就导致了并发。我们甚至能够在一个进程中执行多个控制流。

- **单处理器系统**  处理器必须在多个任务间切换，大多数实际计算也都是由一个处理器完成。

![](/notes/img/1.12.png)

- **多处理器系统**  当构建一个由单操作系统内核控制的多处理器组成的系统时，我们就得到了一个多处理器系统。

  - **多核处理器** 是将多个 CPU（“核”）集成到一个集成电路芯片上。
  ![](/notes/img/1.13.png)

  - **超线程** 又称**同时多线程**，是一项允许一个 CPU 执行多个控制流的技术。

多处理器可以从两方面提高程序性能：

- 减少了执行多个任务时模拟并发的需要

- 使应用程序运行得更快——当程序是以多线程书写时，这些线程可以并行地高效执行。

##### 2.指令集并行

在较低层次上，现代处理器可以同时执行多条指令的属性称为**指令级并行**。

##### 3.单指令、多数据并行

在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式被称为**单指令、多数据**，即 SIMD 并行。


#### 1.9.3 计算机系统中抽象的重要性

**抽象**的使用是计算机科学中最为重要的概念之一。

- **文件**是对 I/O 设备的抽象。

- **虚拟内存**是对程序存储器的抽象。

- **进程**是对一个正在运行的程序的抽象。

- **虚拟机**是对整个计算机的抽象。
